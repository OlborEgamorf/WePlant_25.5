---
title: "Regression logistique"
format: html
editor: visual
---

```{r}
#install.packages("randomForest")
library(randomForest)
# install.packages("pROC")
library(pROC)
# install.packages("MASS")
library(MASS)
# install.packages("caret")
library(caret)
# install.packages("rpart")
# install.packages("rpart.plot") # Pour visualiser l'arbre
library(rpart)
library(rpart.plot)

```

# 1. Chargement des données

```{r}
# Nettoyer l'environnement (optionnel)
rm(list = ls())

# Charger le jeu de données
plant_data <- read.csv2("../data/plant_growth_data.csv", 
                       header = TRUE, 
                       sep = ",",
                       stringsAsFactors = FALSE)

# Aperçu des premières lignes
head(plant_data)

# Structure des données
str(plant_data)

```

# 2. Préparation des variables

```{r}
# Convertir les variables en facteurs ou numériques selon vos besoins
# Exemple :
plant_data$Growth_Milestone <- as.factor(plant_data$Growth_Milestone)
plant_data$Soil_Type <- as.factor(plant_data$Soil_Type)
plant_data$Water_Frequency <- as.factor(plant_data$Water_Frequency)

# Si vous avez d'autres variables, adaptez ici :
# plant_data$Fertilizer <- as.factor(plant_data$Fertilizer)

# Vérifier la distribution de la variable cible
table(plant_data$Growth_Milestone)

```

# 3. Régression logistique simple

```{r}
# Modèle de régression logistique de base (sans interaction)
# Adaptez la formule selon vos variables explicatives
model_simple <- glm(Growth_Milestone ~ Soil_Type + Water_Frequency,
                    data = plant_data, family = binomial)

summary(model_simple)

```

# 4. Ajout d’interactions

```{r}
# Modèle avec interaction
model_interaction <- glm(Growth_Milestone ~ Soil_Type * Water_Frequency,
                         data = plant_data, family = binomial)

summary(model_interaction)

# Comparer via AIC
AIC(model_simple, model_interaction)

```

# 5. Évaluation du modèle

## 5.1 Prédictions et matrice de confusion

```{r}
# Probabilités prédites
plant_data$prob <- predict(model_simple, type = "response")

# Choisir un seuil (0.5 par défaut)
threshold <- 0.5
plant_data$pred_class <- ifelse(plant_data$prob > threshold, 1, 0)

# Matrice de confusion
table(Préel = plant_data$Growth_Milestone, 
      Prédit = plant_data$pred_class)

```

**Calcul d’Accuracy** (taux de bonne classification) :

```{r}
accuracy <- mean(plant_data$pred_class == plant_data$Growth_Milestone)
accuracy

```

## 5.2 Courbe ROC et AUC

```{r}
# Installer et charger pROC si nécessaire


roc_obj <- roc(plant_data$Growth_Milestone, plant_data$prob)
plot(roc_obj, main = "Courbe ROC du modèle logistique")
auc_value <- auc(roc_obj)
auc_value

```

# 6. Rajout d'une variable

```{r}
# Modèle avec interactions à trois variables
model_full <- glm(Growth_Milestone ~ Soil_Type * Water_Frequency * Fertilizer_Type,
                  data = plant_data, family = binomial)

summary(model_full)

```

# 7. Sélection de modèle

```{r}

# Définir un modèle "complet" (full) avec toutes les variables et interactions possibles
model_full <- glm(Growth_Milestone ~ Soil_Type * Water_Frequency * Fertilizer_Type,
                  data = plant_data, family = binomial)

# Définir un modèle "réduit" (null) qui n'a pas de prédicteurs (juste l'intercept)
model_null <- glm(Growth_Milestone ~ 1,
                  data = plant_data, family = binomial)

# Sélection stepwise à partir du modèle null vers le full (direction ascendante)
model_step_forward <- stepAIC(model_null, 
                              scope = list(lower = model_null, upper = model_full),
                              direction = "forward",
                              trace = FALSE)
summary(model_step_forward)

# Sélection stepwise à partir du modèle full vers le null (direction descendante)
model_step_backward <- stepAIC(model_full,
                               direction = "backward",
                               trace = FALSE)
summary(model_step_backward)

# Sélection stepwise "both" (ascendante et descendante)
model_step_both <- stepAIC(model_null,
                           scope = list(lower = model_null, upper = model_full),
                           direction = "both",
                           trace = FALSE)
summary(model_step_both)

```

# 8. Validation Croisée

```{r}
# Supposons que la variable soit encore numérique ou déjà facteur avec niveaux "0" et "1"
plant_data$Growth_Milestone <- factor(plant_data$Growth_Milestone, 
                                      levels = c(0, 1), 
                                      labels = c("No", "Yes"))

# Vérifiez les nouveaux niveaux
levels(plant_data$Growth_Milestone)
# [1] "No"  "Yes"

```

```{r}


# Créer un contrôleur de validation croisée (ici 10-fold)
train_control <- trainControl(method = "cv", number = 10, 
                              summaryFunction = twoClassSummary,
                              classProbs = TRUE,  # important pour calculer AUC
                              savePredictions = TRUE)

 
plant_data$Growth_Milestone <- as.factor(plant_data$Growth_Milestone)

# Définir la formule
form <- as.formula("Growth_Milestone ~ Soil_Type + Water_Frequency + Fertilizer_Type")

# Entraîner un modèle logistique avec caret
model_caret <- train(form,
                     data = plant_data,
                     method = "glm",
                     family = "binomial",
                     trControl = train_control,
                     metric = "ROC")  # On optimise l'AUC

# Résultats
model_caret

```

# 9. Comparaison avec d'autres algorithmes

## 9.1 Arbre de décision

```{r}


# Entraîner un arbre de décision avec caret
model_tree <- train(form,
                    data = plant_data,
                    method = "rpart",
                    trControl = train_control,
                    metric = "ROC")

model_tree
rpart.plot(model_tree$finalModel)  # Visualiser l'arbre

```

## 9.2 Random Forest

```{r}

model_rf <- train(form,
                  data = plant_data,
                  method = "rf",
                  trControl = train_control,
                  metric = "ROC")

model_rf

```
